{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "     \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/petDataset/'  \n",
        "\n",
        "image_size = (224,224)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "\n",
        "validation_batches = train_datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')\n",
        "\n",
        "\n",
        "test_batches = train_datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical', \n",
        "        shuffle=False,\n",
        "        subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdAfdEqnpKbJ",
        "outputId": "675e1850-f2a0-4a53-a1cc-1a8e426585f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Found 3561 images belonging to 3 classes.\n",
            "Found 889 images belonging to 3 classes.\n",
            "Found 889 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8PJ6BxKpXHMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOE13XElo6-I",
        "outputId": "e5959a0b-b5ec-4773-be13-78a229677ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 13s 545ms/step - loss: 0.7852 - acc: 0.6352 - val_loss: 4.9724 - val_acc: 0.3108\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 0.1259 - acc: 0.9609 - val_loss: 19.1512 - val_acc: 0.2973\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 3s 304ms/step - loss: 0.0684 - acc: 0.9805 - val_loss: 13.5531 - val_acc: 0.4730\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0381 - acc: 0.9870 - val_loss: 8.6109 - val_acc: 0.5405\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 0.0196 - acc: 0.9967 - val_loss: 6.2930 - val_acc: 0.5541\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 0.0216 - acc: 0.9935 - val_loss: 1.3110 - val_acc: 0.8649\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 3s 312ms/step - loss: 0.0445 - acc: 0.9870 - val_loss: 1.0357 - val_acc: 0.9865\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 0.0144 - acc: 0.9967 - val_loss: 1.8376 - val_acc: 0.9730\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 3s 310ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 1.7006 - val_acc: 0.9595\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 0.0335 - acc: 0.9935 - val_loss: 1.1580 - val_acc: 0.9730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe328168c70>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "ResNet_model = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "from tensorflow.keras import Model \n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# The last 15 layers fine tune\n",
        "for layer in ResNet_model.layers[:-15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = ResNet_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output  = Dense(units=4, activation='softmax')(x)\n",
        "model = Model(ResNet_model.input, output)\n",
        "\n",
        "model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=\"acc\")\n",
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches, validation_steps=len(validation_batches), epochs=10, verbose=1 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7sOtFVOPT1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSjqsnePHQ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "l6WTVrWDHRNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_d=DenseNet121(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) \n",
        "\n",
        "x=model_d.output\n",
        "\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "x= Dense(1024,activation='relu')(x) \n",
        "x= Dense(512,activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "\n",
        "preds=Dense(4,activation='softmax')(x) #FC-layer\n",
        "\n",
        "model=Model(inputs=model_d.input,outputs=preds)\n",
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model.summary()\n",
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches, validation_steps=len(validation_batches), epochs=20, verbose=1 )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-MSy0MkHew0",
        "outputId": "265e22bd-a266-49b3-b4a8-f3583da468db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 17s 582ms/step - loss: 0.8324 - accuracy: 0.7264 - val_loss: 4.1379 - val_accuracy: 0.2297\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 4s 379ms/step - loss: 0.3068 - accuracy: 0.9121 - val_loss: 4.1738 - val_accuracy: 0.2432\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.2311 - accuracy: 0.9414 - val_loss: 6.2356 - val_accuracy: 0.1351\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 4s 384ms/step - loss: 0.1890 - accuracy: 0.9511 - val_loss: 7.5473 - val_accuracy: 0.3378\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 4s 385ms/step - loss: 0.1371 - accuracy: 0.9739 - val_loss: 9.7218 - val_accuracy: 0.3378\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 4s 403ms/step - loss: 0.1134 - accuracy: 0.9609 - val_loss: 15.9595 - val_accuracy: 0.1351\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.1709 - accuracy: 0.9577 - val_loss: 47.2737 - val_accuracy: 0.1351\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 4s 391ms/step - loss: 0.1870 - accuracy: 0.9479 - val_loss: 15.7583 - val_accuracy: 0.1351\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 4s 393ms/step - loss: 0.2857 - accuracy: 0.9283 - val_loss: 7.6586 - val_accuracy: 0.2297\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 4s 390ms/step - loss: 0.1141 - accuracy: 0.9772 - val_loss: 10.6311 - val_accuracy: 0.2297\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.0907 - accuracy: 0.9772 - val_loss: 14.0110 - val_accuracy: 0.2297\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 4s 388ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 14.6241 - val_accuracy: 0.2973\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 4s 385ms/step - loss: 0.0305 - accuracy: 0.9837 - val_loss: 19.3138 - val_accuracy: 0.2973\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 4s 385ms/step - loss: 0.0218 - accuracy: 0.9902 - val_loss: 16.7366 - val_accuracy: 0.2973\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 4s 385ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 12.8262 - val_accuracy: 0.2297\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 4s 382ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 10.5417 - val_accuracy: 0.2297\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 9.1804 - val_accuracy: 0.2297\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 4s 382ms/step - loss: 0.0154 - accuracy: 0.9935 - val_loss: 7.1046 - val_accuracy: 0.2297\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 4s 383ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.3701 - val_accuracy: 0.2297\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 6.2303 - val_accuracy: 0.2297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe326c63280>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZ7g7VbKIDJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A02fftGDXIrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "ResNet_model = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "from tensorflow.keras import Model \n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# The last 15 layers fine tune\n",
        "for layer in ResNet_model.layers[:-15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = ResNet_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output  = Dense(units=3, activation='softmax')(x)\n",
        "model = Model(ResNet_model.input, output)\n",
        "\n",
        "model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=\"acc\")\n",
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches, validation_steps=len(validation_batches), epochs=30, verbose=1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2oJeToXIye",
        "outputId": "dd1851a3-f0de-44c6-e030-e21d42bf36d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 [==============================] - 44s 314ms/step - loss: 0.5777 - acc: 0.7686 - val_loss: 3.6649 - val_acc: 0.5028\n",
            "Epoch 2/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.1898 - acc: 0.9464 - val_loss: 2.5328 - val_acc: 0.5872\n",
            "Epoch 3/30\n",
            "112/112 [==============================] - 32s 287ms/step - loss: 0.1146 - acc: 0.9657 - val_loss: 1.8555 - val_acc: 0.6535\n",
            "Epoch 4/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.0969 - acc: 0.9680 - val_loss: 2.9802 - val_acc: 0.6547\n",
            "Epoch 5/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0554 - acc: 0.9829 - val_loss: 1.1148 - val_acc: 0.7829\n",
            "Epoch 6/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.1006 - acc: 0.9697 - val_loss: 2.5794 - val_acc: 0.6817\n",
            "Epoch 7/30\n",
            "112/112 [==============================] - 33s 291ms/step - loss: 0.0654 - acc: 0.9832 - val_loss: 0.3694 - val_acc: 0.8965\n",
            "Epoch 8/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0520 - acc: 0.9868 - val_loss: 0.4811 - val_acc: 0.8583\n",
            "Epoch 9/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0221 - acc: 0.9941 - val_loss: 1.1213 - val_acc: 0.8605\n",
            "Epoch 10/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0349 - acc: 0.9896 - val_loss: 0.4983 - val_acc: 0.8628\n",
            "Epoch 11/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0225 - acc: 0.9935 - val_loss: 0.7599 - val_acc: 0.8875\n",
            "Epoch 12/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0766 - acc: 0.9775 - val_loss: 1.5731 - val_acc: 0.7503\n",
            "Epoch 13/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0237 - acc: 0.9944 - val_loss: 0.6025 - val_acc: 0.8808\n",
            "Epoch 14/30\n",
            "112/112 [==============================] - 33s 291ms/step - loss: 0.0511 - acc: 0.9846 - val_loss: 0.2196 - val_acc: 0.9303\n",
            "Epoch 15/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0457 - acc: 0.9860 - val_loss: 1.7968 - val_acc: 0.7132\n",
            "Epoch 16/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0196 - acc: 0.9955 - val_loss: 0.8486 - val_acc: 0.8830\n",
            "Epoch 17/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0258 - acc: 0.9927 - val_loss: 0.3746 - val_acc: 0.8920\n",
            "Epoch 18/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0535 - acc: 0.9860 - val_loss: 0.4999 - val_acc: 0.8898\n",
            "Epoch 19/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0315 - acc: 0.9924 - val_loss: 0.8383 - val_acc: 0.7840\n",
            "Epoch 20/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.0358 - acc: 0.9890 - val_loss: 1.5041 - val_acc: 0.7413\n",
            "Epoch 21/30\n",
            "112/112 [==============================] - 33s 291ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.3259 - val_acc: 0.9111\n",
            "Epoch 22/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.0237 - acc: 0.9933 - val_loss: 0.6963 - val_acc: 0.8650\n",
            "Epoch 23/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0273 - acc: 0.9924 - val_loss: 0.4319 - val_acc: 0.8695\n",
            "Epoch 24/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0109 - acc: 0.9961 - val_loss: 0.5639 - val_acc: 0.8965\n",
            "Epoch 25/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0344 - acc: 0.9952 - val_loss: 1.6936 - val_acc: 0.7807\n",
            "Epoch 26/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 0.0241 - acc: 0.9944 - val_loss: 0.4318 - val_acc: 0.8875\n",
            "Epoch 27/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.0195 - acc: 0.9933 - val_loss: 1.0207 - val_acc: 0.8065\n",
            "Epoch 28/30\n",
            "112/112 [==============================] - 32s 289ms/step - loss: 0.0126 - acc: 0.9978 - val_loss: 1.1590 - val_acc: 0.8043\n",
            "Epoch 29/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 4.0058e-04 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.9055\n",
            "Epoch 30/30\n",
            "112/112 [==============================] - 32s 288ms/step - loss: 2.1965e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.9100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff65a3b2220>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_d=DenseNet121(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) \n",
        "\n",
        "x=model_d.output\n",
        "\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "x= Dense(1024,activation='relu')(x) \n",
        "x= Dense(512,activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "\n",
        "preds=Dense(3,activation='softmax')(x) #FC-layer\n",
        "\n",
        "model=Model(inputs=model_d.input,outputs=preds)\n",
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model.summary()\n",
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches, validation_steps=len(validation_batches), epochs=30, verbose=1 )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FoKCEZOXI1Q",
        "outputId": "52c83b01-6718-4a8c-eaf0-c71bbb8ac2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 [==============================] - 57s 400ms/step - loss: 1.1517 - accuracy: 0.5746 - val_loss: 3.5017 - val_accuracy: 0.2542\n",
            "Epoch 2/30\n",
            "112/112 [==============================] - 42s 377ms/step - loss: 0.5103 - accuracy: 0.8267 - val_loss: 4.5597 - val_accuracy: 0.2823\n",
            "Epoch 3/30\n",
            "112/112 [==============================] - 42s 379ms/step - loss: 0.3067 - accuracy: 0.9009 - val_loss: 6.4798 - val_accuracy: 0.2171\n",
            "Epoch 4/30\n",
            "112/112 [==============================] - 43s 383ms/step - loss: 0.2308 - accuracy: 0.9186 - val_loss: 7.4793 - val_accuracy: 0.2857\n",
            "Epoch 5/30\n",
            "112/112 [==============================] - 42s 377ms/step - loss: 0.1332 - accuracy: 0.9531 - val_loss: 9.0898 - val_accuracy: 0.3712\n",
            "Epoch 6/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.1482 - accuracy: 0.9503 - val_loss: 2.9782 - val_accuracy: 0.5973\n",
            "Epoch 7/30\n",
            "112/112 [==============================] - 43s 381ms/step - loss: 0.1130 - accuracy: 0.9621 - val_loss: 7.2683 - val_accuracy: 0.6299\n",
            "Epoch 8/30\n",
            "112/112 [==============================] - 43s 385ms/step - loss: 0.0828 - accuracy: 0.9702 - val_loss: 2.1167 - val_accuracy: 0.5669\n",
            "Epoch 9/30\n",
            "112/112 [==============================] - 42s 379ms/step - loss: 0.1063 - accuracy: 0.9641 - val_loss: 2.3953 - val_accuracy: 0.6468\n",
            "Epoch 10/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.1112 - accuracy: 0.9624 - val_loss: 0.9788 - val_accuracy: 0.6907\n",
            "Epoch 11/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0982 - accuracy: 0.9708 - val_loss: 0.9407 - val_accuracy: 0.7233\n",
            "Epoch 12/30\n",
            "112/112 [==============================] - 42s 379ms/step - loss: 0.1159 - accuracy: 0.9593 - val_loss: 0.5688 - val_accuracy: 0.8234\n",
            "Epoch 13/30\n",
            "112/112 [==============================] - 43s 381ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 2.1337 - val_accuracy: 0.6940\n",
            "Epoch 14/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0476 - accuracy: 0.9862 - val_loss: 1.1372 - val_accuracy: 0.7998\n",
            "Epoch 15/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0783 - accuracy: 0.9725 - val_loss: 3.8296 - val_accuracy: 0.6749\n",
            "Epoch 16/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0846 - accuracy: 0.9733 - val_loss: 1.4358 - val_accuracy: 0.6490\n",
            "Epoch 17/30\n",
            "112/112 [==============================] - 42s 377ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.3633 - val_accuracy: 0.8751\n",
            "Epoch 18/30\n",
            "112/112 [==============================] - 43s 381ms/step - loss: 0.0690 - accuracy: 0.9773 - val_loss: 0.2428 - val_accuracy: 0.9044\n",
            "Epoch 19/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.7342 - val_accuracy: 0.8144\n",
            "Epoch 20/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0498 - accuracy: 0.9854 - val_loss: 0.5340 - val_accuracy: 0.8380\n",
            "Epoch 21/30\n",
            "112/112 [==============================] - 43s 380ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.2662 - val_accuracy: 0.9258\n",
            "Epoch 22/30\n",
            "112/112 [==============================] - 43s 379ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.9446 - val_accuracy: 0.7312\n",
            "Epoch 23/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.2272 - val_accuracy: 0.9381\n",
            "Epoch 24/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.7448 - val_accuracy: 0.7357\n",
            "Epoch 25/30\n",
            "112/112 [==============================] - 45s 401ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 2.1076 - val_accuracy: 0.7649\n",
            "Epoch 26/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0767 - accuracy: 0.9750 - val_loss: 5.0877 - val_accuracy: 0.4533\n",
            "Epoch 27/30\n",
            "112/112 [==============================] - 43s 381ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.2905 - val_accuracy: 0.9213\n",
            "Epoch 28/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.5586 - val_accuracy: 0.8448\n",
            "Epoch 29/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 3.1416 - val_accuracy: 0.7188\n",
            "Epoch 30/30\n",
            "112/112 [==============================] - 42s 378ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.5957 - val_accuracy: 0.8740\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8c55a4190>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
        "from keras import applications\n",
        "input_shape = (ROWS, COLS, 3)\n",
        "nclass = len(train_gen.class_indices)\n",
        "\n",
        "base_model = applications.InceptionV3(weights='imagenet', \n",
        "                                include_top=False, \n",
        "                                input_shape=(ROWS, COLS,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(base_model)\n",
        "add_model.add(GlobalAveragePooling2D())\n",
        "add_model.add(Dropout(0.5))\n",
        "add_model.add(Dense(nclass, \n",
        "                    activation='softmax'))\n",
        "\n",
        "model = add_model\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=optimizers.SGD(lr=1e-4, \n",
        "                                       momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1OjhjW5V_n-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches, validation_steps=len(validation_batches), epochs=30, verbose=1 )\n"
      ],
      "metadata": {
        "id": "Fhtsm4FY_2BB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}